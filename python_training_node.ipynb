{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6975ae06-82d8-4b20-a5b7-bb4296451d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from CybORG import CybORG\n",
    "# from CybORG.Simulator.Scenarios.DroneSwarmScenarioGenerator import DroneSwarmScenarioGenerator\n",
    "# from CybORG.Agents.SimpleAgents.RedDroneWorm import RedDroneWormAgent\n",
    "# from CybORG.Agents.Wrappers import PettingZooParallelWrapper\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "# from ipaddress import IPv4Address\n",
    "import random\n",
    "import logging\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd8be1-62eb-4bbf-bb71-be059a394214",
   "metadata": {},
   "source": [
    "# Train GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9fe629",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd179ed-bc79-4074-8b19-94bacd3a42d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 14000\n",
      "Test dataset length: 6000\n"
     ]
    }
   ],
   "source": [
    "filename = './data/dataset_python_node'\n",
    "# testfile = '../Data/testmulti'\n",
    "\n",
    "\n",
    "\n",
    "combined_dataset = torch.load(f'{filename}.pt', weights_only=False)\n",
    "# testset = torch.load(f'{testfile}.pt', weights_only=False)\n",
    "\n",
    "\n",
    "\n",
    "# combined_dataset = dataset + testset\n",
    "# print(f\"Combined dataset length: {len(combined_dataset)}\")\n",
    "random.shuffle(combined_dataset)\n",
    "\n",
    "size = len(combined_dataset)\n",
    "train_size = int(0.7 * size)\n",
    "\n",
    "dataset = combined_dataset[:train_size]\n",
    "testset = combined_dataset[train_size:]\n",
    "print(f\"Train dataset length: {len(dataset)}\")\n",
    "print(f\"Test dataset length: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eaba0b-0884-47d3-b70f-90b0a5abf29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 84], num_nodes=18, x=[18, 110], y=[18])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f73ac4-5548-4004-b36d-288e220c18a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "\n",
      "Data(edge_index=[2, 108], num_nodes=18, x=[18, 110], y=[18])\n",
      "=============================================================\n",
      "Number of nodes: 18\n",
      "Number of edges: 108\n",
      "Average node degree: 6.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "\n",
    "for data in dataset:\n",
    "    delattr(data, 'feature')\n",
    "\n",
    "\n",
    "print(len(dataset))\n",
    "data = dataset[10]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fb4ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 14000\n",
      "Number of test graphs: 6000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# random.shuffle(dataset)\n",
    "# random.shuffle(testset)\n",
    "# train_dataset = dataset[:12000]\n",
    "# test_dataset = dataset[12000:]\n",
    "\n",
    "# size = len(dataset)\n",
    "# size = size - size//4\n",
    "\n",
    "train_dataset = dataset\n",
    "test_dataset = testset\n",
    "\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3273c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    if data.size(1) != 18:\n",
    "        print(f\"Warning: Data shape {data.shape} is not 18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733f7409-47ab-4dd8-abc5-bf58ba570fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in train dataset: 110\n",
      "Number of classes detected: 3\n",
      "--------------Train--------------\n",
      "\u001b[1mTotal nodes: \u001b[0m252000\n",
      "\u001b[1mPercent of Not Compromised: \u001b[0m0.3519 (88678 nodes)\n",
      "\u001b[1mPercent of Compromised: \u001b[0m0.0155 (3912 nodes)\n",
      "\u001b[1mPercent of Highly Compromised: \u001b[0m0.6326 (159410 nodes)\n",
      "\n",
      "--------------Test--------------\n",
      "\u001b[1mTotal nodes: \u001b[0m108000\n",
      "\u001b[1mPercent of Not Compromised: \u001b[0m0.3513 (37939 nodes)\n",
      "\u001b[1mPercent of Compromised: \u001b[0m0.0153 (1653 nodes)\n",
      "\u001b[1mPercent of Highly Compromised: \u001b[0m0.6334 (68408 nodes)\n",
      "\n",
      "Class distribution:\n",
      "Not Compromised: █████████████████ 35.19%\n",
      "Compromised:  1.55%\n",
      "Highly Compromised: ███████████████████████████████ 63.26%\n"
     ]
    }
   ],
   "source": [
    "# test_dataset = torch.load(f\"test_gl_selected.pt\", weights_only=False)\n",
    "# train_dataset = torch.load(f\"train_gl_selected.pt\", weights_only=False)\n",
    "\n",
    "test_dataset = testset\n",
    "train_dataset = dataset\n",
    "\n",
    "print(f'Number of features in train dataset: {train_dataset[0].x.shape[1]}')\n",
    "\n",
    "# Determine the number of classes in the dataset\n",
    "unique_classes = set()\n",
    "for t in train_dataset:\n",
    "    unique_classes.update(t.y.unique().cpu().numpy())\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"Number of classes detected: {num_classes}\")\n",
    "\n",
    "# Test dataset statistics\n",
    "test_total_nodes = 0\n",
    "test_class_counts = {i: 0 for i in range(num_classes)}\n",
    "\n",
    "for t in test_dataset:\n",
    "    test_total_nodes += t.y.size(0)\n",
    "    for class_idx in range(num_classes):\n",
    "        test_class_counts[class_idx] += (t.y == class_idx).sum().item()\n",
    "\n",
    "# Train dataset statistics\n",
    "train_total_nodes = 0\n",
    "train_class_counts = {i: 0 for i in range(num_classes)}\n",
    "\n",
    "for t in train_dataset:\n",
    "    train_total_nodes += t.y.size(0)\n",
    "    for class_idx in range(num_classes):\n",
    "        train_class_counts[class_idx] += (t.y == class_idx).sum().item()\n",
    "\n",
    "# Print statistics with class labels\n",
    "class_labels = [\"Not Compromised\", \"Compromised\", \"Highly Compromised\"] if num_classes == 3 else [f\"Class {i}\" for i in range(num_classes)]\n",
    "\n",
    "print('--------------Train--------------')\n",
    "print(f'\\033[1mTotal nodes: \\033[0m{train_total_nodes}')\n",
    "for i in range(num_classes):\n",
    "    percentage = train_class_counts[i]/train_total_nodes if train_total_nodes > 0 else 0\n",
    "    print(f'\\033[1mPercent of {class_labels[i]}: \\033[0m{percentage:.4f} ({train_class_counts[i]} nodes)')\n",
    "\n",
    "print('\\n--------------Test--------------')\n",
    "print(f'\\033[1mTotal nodes: \\033[0m{test_total_nodes}')\n",
    "for i in range(num_classes):\n",
    "    percentage = test_class_counts[i]/test_total_nodes if test_total_nodes > 0 else 0\n",
    "    print(f'\\033[1mPercent of {class_labels[i]}: \\033[0m{percentage:.4f} ({test_class_counts[i]} nodes)')\n",
    "\n",
    "# Print class distribution visualization if desired\n",
    "print(\"\\nClass distribution:\")\n",
    "max_bar_length = 50  # maximum bar length in characters\n",
    "for i in range(num_classes):\n",
    "    train_pct = train_class_counts[i]/train_total_nodes if train_total_nodes > 0 else 0\n",
    "    bar_length = int(train_pct * max_bar_length)\n",
    "    print(f\"{class_labels[i]}: {'█' * bar_length} {train_pct:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ca1f5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "282f09a1-471b-4af4-b740-62a1642ea5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "GCN(\n",
      "  (conv1): GCNConv(110, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (conv3): GCNConv(32, 32)\n",
      "  (lin): Linear(in_features=32, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Specify device manually\n",
    "use_gpu = True # Set to False to use CPU\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# DataLoader (ensure `train_dataset` and `test_dataset` are loaded correctly)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "input_dim = len(train_dataset[0].x[0])\n",
    "\n",
    "# Define the GCN model for node classification\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=input_dim,hidden_channels=32,num_classes=3):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(input_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)  # 2 classes: compromised or not\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # 2. Node-level classification\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=32)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50f932-1389-42a8-af60-38bdc410cd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [0.12384162044693987, 2.8072666712662917, 0.0688917082867683]\n",
      "Epoch: 001, Train Loss: 2.5239, Test Loss: 0.8993, Train Acc: 0.4606, Test Acc: 0.6859, Precision: 0.5439, Recall: 0.5811\n",
      "Epoch: 002, Train Loss: 1.2263, Test Loss: 0.8586, Train Acc: 0.5353, Test Acc: 0.6328, Precision: 0.5677, Recall: 0.5981\n",
      "Epoch: 003, Train Loss: 1.0389, Test Loss: 0.8518, Train Acc: 0.5587, Test Acc: 0.6358, Precision: 0.5706, Recall: 0.6038\n",
      "Epoch: 004, Train Loss: 0.9748, Test Loss: 0.8409, Train Acc: 0.5770, Test Acc: 0.6297, Precision: 0.5762, Recall: 0.6201\n",
      "Epoch: 005, Train Loss: 0.9391, Test Loss: 0.8331, Train Acc: 0.5832, Test Acc: 0.6162, Precision: 0.5827, Recall: 0.6276\n",
      "Epoch: 006, Train Loss: 0.9109, Test Loss: 0.8256, Train Acc: 0.5905, Test Acc: 0.6149, Precision: 0.5847, Recall: 0.6319\n",
      "Epoch: 007, Train Loss: 0.8965, Test Loss: 0.8200, Train Acc: 0.5961, Test Acc: 0.6077, Precision: 0.5886, Recall: 0.6368\n",
      "Epoch: 008, Train Loss: 0.8819, Test Loss: 0.8117, Train Acc: 0.5907, Test Acc: 0.6208, Precision: 0.5828, Recall: 0.6384\n",
      "Epoch: 009, Train Loss: 0.8717, Test Loss: 0.8082, Train Acc: 0.6012, Test Acc: 0.6094, Precision: 0.5893, Recall: 0.6396\n",
      "Epoch: 010, Train Loss: 0.8600, Test Loss: 0.8023, Train Acc: 0.6036, Test Acc: 0.6144, Precision: 0.5877, Recall: 0.6421\n",
      "Epoch: 011, Train Loss: 0.8560, Test Loss: 0.7998, Train Acc: 0.6024, Test Acc: 0.6146, Precision: 0.5886, Recall: 0.6417\n",
      "Epoch: 012, Train Loss: 0.8477, Test Loss: 0.7944, Train Acc: 0.6088, Test Acc: 0.6185, Precision: 0.5876, Recall: 0.6423\n",
      "Epoch: 013, Train Loss: 0.8417, Test Loss: 0.7899, Train Acc: 0.6074, Test Acc: 0.6172, Precision: 0.5876, Recall: 0.6406\n",
      "Epoch: 014, Train Loss: 0.8339, Test Loss: 0.7846, Train Acc: 0.6076, Test Acc: 0.6333, Precision: 0.5825, Recall: 0.6437\n",
      "Epoch: 015, Train Loss: 0.8285, Test Loss: 0.7816, Train Acc: 0.6143, Test Acc: 0.6394, Precision: 0.5810, Recall: 0.6453\n",
      "Epoch: 016, Train Loss: 0.8205, Test Loss: 0.7749, Train Acc: 0.6195, Test Acc: 0.6338, Precision: 0.5827, Recall: 0.6473\n",
      "Epoch: 017, Train Loss: 0.8168, Test Loss: 0.7717, Train Acc: 0.6174, Test Acc: 0.6241, Precision: 0.5858, Recall: 0.6449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "num_classes = 3\n",
    "# Initialize the model, optimizer, and loss function\n",
    "model = GCN(hidden_channels=64, num_classes=num_classes).to(device)  # Make sure GCN uses correct number of classes\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Calculate class weights inversely proportional to class frequencies\n",
    "class_weights = []\n",
    "for class_idx in range(num_classes):\n",
    "    # Get counts for this class\n",
    "    class_count = train_class_counts[class_idx]\n",
    "    # Calculate weight (inversely proportional to frequency)\n",
    "    if class_count > 0:\n",
    "        weight = train_total_nodes / (num_classes * class_count)\n",
    "    else:\n",
    "        weight = 1.0\n",
    "    class_weights.append(weight)\n",
    "\n",
    "# Normalize weights\n",
    "class_weights = [w / sum(class_weights) * num_classes for w in class_weights]\n",
    "class_weights_tensor = torch.tensor(class_weights, device=device)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Use weighted cross entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "losses = []  # Training losses\n",
    "test_losses = []  # Test losses\n",
    "accs = []  # Test accuracies\n",
    "precisions = []  # Test precisions\n",
    "recalls = []  # Test recalls\n",
    "train_accs = []  # Training accuracies\n",
    "\n",
    "# Define the training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_nodes = 0\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)  # Move batch data to GPU\n",
    "        out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        total_loss += loss.item() * data.num_nodes  # Accumulate loss for this epoch.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        \n",
    "        # Calculate accuracy for node predictions\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct = int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        total_correct += correct\n",
    "        total_nodes += data.num_nodes\n",
    "    \n",
    "    avg_loss = total_loss / total_nodes  # Calculate average loss per node\n",
    "    acc = total_correct / total_nodes  # Calculate accuracy per node\n",
    "    train_accs.append(acc)  # Append accuracy to the list.\n",
    "    losses.append(avg_loss)  # Append the average loss to the list.\n",
    "\n",
    "# Define the testing loop\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    total_nodes = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation during evaluation.\n",
    "        for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            data = data.to(device)  # Move batch data to GPU\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out, data.y)  # Compute the loss for the batch.\n",
    "            total_loss += loss.item() * data.num_nodes  # Accumulate test loss.\n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct = int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "            total_correct += correct\n",
    "            total_nodes += data.num_nodes\n",
    "\n",
    "            # Collect predictions and true labels for precision and recall\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total_nodes  # Calculate average loss per node\n",
    "    test_losses.append(avg_loss)  # Append the average test loss to the list.\n",
    "    acc = total_correct / total_nodes  # Calculate accuracy per node\n",
    "    accs.append(acc)  # Append accuracy to the list.\n",
    "\n",
    "    # Compute precision and recall\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "    return acc, avg_loss, precision, recall\n",
    "\n",
    "# Training and testing loop\n",
    "for epoch in range(1, 1001):\n",
    "    train()\n",
    "    test_acc, test_loss, precision, recall = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {losses[-1]:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accs[-1]:.4f}, Test Acc: {test_acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f2821-6520-405a-b862-d9d8ea644927",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1110016-0917-4e8d-9c07-d6d5f56fde85",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1000,) and (19,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sm/qblrjhws6qnc592v26gpg_y00000gn/T/ipykernel_31426/3380387394.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the loss curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/intel/lib/python3.12/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3825\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3826\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3827\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3828\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3829\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/intel/lib/python3.12/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/intel/lib/python3.12/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/intel/lib/python3.12/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              \u001b[0;34mf\"\u001b[0m\u001b[0;34mhave shapes \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m and \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1000,) and (19,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot(range(1, 1001), losses, label='Training Loss')\n",
    "plt.plot(range(1,1001), test_losses, label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.savefig('../Data/loss_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc70de-0dfe-4bc5-b5c1-bfaafba4e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 1001), accs, label='Test accuracy')\n",
    "# plt.plot(range(1, 101), train_accs, label='Train accuracy')\n",
    "print(f'Max accuracy: {max(accs)}')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "# plt.savefig('../Data/accuracy_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea127ab-fef7-4ad4-ab82-caa9f996774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 1001), precisions, label='Precision')\n",
    "plt.plot(range(1, 1001), recalls, label='Recall')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylabel('Precision/Recall')\n",
    "plt.title('Precision and Recall Curves')\n",
    "plt.savefig('../Data/precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fbf68a-a8ea-406b-8b0f-ee1c27c23f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74ec10-10c1-4c14-8703-213ae4377ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdc312-c6b6-4482-b67a-8e85ac0cb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
